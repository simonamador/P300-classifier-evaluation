{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simonamador/P300-classifier-evaluation/blob/main/lockedin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# P300 analysis on LIS patients\n",
        "Working with a dataset of two subject, which consists of 4 registers each:\n",
        "\n",
        "\n",
        "*   2 low accuracy signals\n",
        "*   2 high accuracy signals\n",
        "\n",
        "\n",
        "The data aquisition was done with a 256 Hz sample rate. 3 conditions indicated by trigger data:\n",
        "\n",
        "\n",
        "1.   Distractor (-1)\n",
        "2.   Nontarget (1)\n",
        "3.   Target (2)"
      ],
      "metadata": {
        "id": "Gz3sYIrmKB2B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing dataset, package installation"
      ],
      "metadata": {
        "id": "zx1PkChLK_v0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJaHPq2YlGn7",
        "outputId": "9e15c49c-8518-4ece-8c59-4bcf159efb85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.9/dist-packages (1.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne) (23.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.9/dist-packages (from mne) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne) (3.7.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (2.27.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.0.7)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->mne) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->mne) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.15)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import mne\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn as sk\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "from scipy.io import loadmat\n",
        "from time import sleep"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "route = '/content/drive/MyDrive/BR41N.IO/files'\n",
        "channels = ['Fz', 'C3', 'Cz', 'C4', 'CP1', 'CPz', 'CP2', 'Pz']\n",
        "fs = 256\n",
        "P1_low1 = loadmat(route+'/P1_low1.mat')\n",
        "P1_low2 = loadmat(route+'/P1_low2.mat')\n",
        "P1_high1 = loadmat(route+'/P1_high1.mat')\n",
        "P1_high2 = loadmat(route+'/P1_high2.mat')\n",
        "P2_low1 = loadmat(route+'/P2_low1.mat')\n",
        "P2_low2 = loadmat(route+'/P2_low2.mat')\n",
        "P2_high1 = loadmat(route+'/P2_high1.mat')\n",
        "P2_high2 = loadmat(route+'/P2_high2.mat')"
      ],
      "metadata": {
        "id": "DzBRwPn0l9P1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "d2167e92-95d9-4d5c-dd68-ebfeb4561c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/BR41N.IO/files/P1_low2.mat'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-d910f79b8b3c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mP1_low2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/P1_low2.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mP1_high1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/P1_high1.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mP1_high2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroute\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/P1_high2.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m    224\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/scipy/io/matlab/_mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             raise OSError(\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/BR41N.IO/files/P1_low2.mat'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing\n",
        "\n",
        "\n",
        "\n",
        "1.   Convert to Volts\n",
        "2.   Remove offset\n",
        "3.   Filtro pasa altas de 1 Hz\n",
        "4.   Filtro ICA\n",
        "5.   Segmentación\n",
        "6.   Normalizacion\n"
      ],
      "metadata": {
        "id": "6-MQC621LSv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(raw, fs):\n",
        "  info = mne.create_info(channels,fs,ch_types='eeg')\n",
        "  infostim = mne.create_info(['STI'], fs, 'stim')\n",
        "\n",
        "  data = raw['y'].transpose()/10**6\n",
        "  data = data - np.mean(data)\n",
        "  n_raw = mne.io.RawArray(data,info)\n",
        "  n_raw = n_raw.copy().filter(l_freq=1, h_freq=None)\n",
        "\n",
        "  ica = mne.preprocessing.ICA(n_components=8, random_state=97, max_iter=800)\n",
        "  ica.fit(n_raw)\n",
        "  ica.plot_sources(n_raw, show_scrollbars=False)\n",
        "  sleep(2)\n",
        "  compex = input('Components to exclude: ')\n",
        "  compex = compex.split(', ')\n",
        "  compex_f = [int(n) for n in compex]\n",
        "  ica.exclude = compex_f\n",
        "\n",
        "  n_raw.load_data()\n",
        "  ica.apply(n_raw)\n",
        "  n_raw.plot(duration=5,show=False)\n",
        "  plt.show()\n",
        "\n",
        "  chex = input('Channels to exclude: ')\n",
        "  chex = chex.split(', ')\n",
        "  n_raw.drop_channels(chex)\n",
        "  n_raw.plot(duration=5,show=False)\n",
        "  plt.show()\n",
        "\n",
        "  trigger = raw['trig'].transpose()\n",
        "  for i in range(trigger.size):\n",
        "    if trigger[0,i] == -1:\n",
        "      trigger[0,i] = 3\n",
        "  \n",
        "  stim_raw = mne.io.RawArray(trigger, infostim)\n",
        "  n_raw.add_channels([stim_raw], force_update_info=True)\n",
        "\n",
        "  #-1 = distractor, 1 = non-target, 2=target\n",
        "  events = mne.find_events(n_raw, stim_channel='STI')\n",
        "  epochs = mne.Epochs(n_raw, events, tmin=-0.1, tmax=0.6)\n",
        "\n",
        "  epochs['1'].plot_image(picks='eeg', combine='mean')\n",
        "  epochs['2'].plot_image(picks='eeg', combine='mean')\n",
        "  epochs['3'].plot_image(picks='eeg', combine='mean')\n",
        "\n",
        "  nontarget = epochs['1'].get_data()\n",
        "  target = epochs['2'].get_data()\n",
        "  dist = epochs['3'].get_data()\n",
        "  return nontarget, target, dist"
      ],
      "metadata": {
        "id": "dJqZgsPFpqhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nt, t, d = preprocessing(P2_high2, fs)"
      ],
      "metadata": {
        "id": "XcHktdYYGZwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def minmax(X):\n",
        "  scaler = sk.preprocessing.MinMaxScaler()\n",
        "  for i in range(X.shape[0]):\n",
        "    X[i,:,:] = scaler.fit_transform(X[i,:,:].transpose()).transpose()\n",
        "  return X"
      ],
      "metadata": {
        "id": "t0JZgogyJ3GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xt = t\n",
        "Xnt = np.concatenate((nt,d))\n",
        "Xt = minmax(Xt)\n",
        "Xnt = minmax(Xnt)\n",
        "yt = np.repeat(1,t.shape[0])\n",
        "ynt = np.concatenate((np.repeat(0,nt.shape[0]),np.repeat(0,d.shape[0])))\n",
        "\n",
        "\n",
        "sz = Xt.shape\n",
        "#Generate matries for training-testing\n",
        "X_tr = np.empty(shape=(round(sz[0]*1.6),sz[1],sz[2],1))\n",
        "X_ts = np.empty(shape=(round(sz[0]*1.6),sz[1],sz[2],1))\n",
        "#Use of permutation to randomly divide the matrix index,\n",
        "#then divide feature and label matrices into training-testing\n",
        "#in an 80/20 ratio. \n",
        "idx = np.random.permutation(sz[0])\n",
        "idx_tr = idx[:round(sz[0]*0.8)]\n",
        "idx_tst, idx_tsnt = idx[round(sz[0]*0.8):], np.random.permutation(int(sz[0]*1.4))\n",
        "X_tr[:,:,:,0] = np.concatenate((Xt[idx_tr,:,:], Xnt[idx_tr,:,:]))\n",
        "y_tr = np.concatenate((yt[idx_tr], ynt[idx_tr]))\n",
        "X_ts[:,:,:,0] = np.concatenate((Xt[idx_tst,:,:], Xnt[idx_tsnt,:,:]))\n",
        "y_ts = np.concatenate((yt[idx_tst],ynt[idx_tsnt]))"
      ],
      "metadata": {
        "id": "KfKSwQY2UYI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Procesamiento"
      ],
      "metadata": {
        "id": "2kNCWFFJOrwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "LDA Classifier"
      ],
      "metadata": {
        "id": "iDvFT3Llhv7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "Xtrain = np.zeros((X_tr.shape[0], X_tr.shape[1]*X_tr.shape[2]))\n",
        "Xtest = np.zeros((X_ts.shape[0], X_ts.shape[1]*X_ts.shape[2]))\n",
        "for i in range(X_tr.shape[0]):\n",
        "  v = X_tr[i,:,:,0].flatten()\n",
        "  Xtrain[i,:] = v\n",
        "\n",
        "for i in range(X_ts.shape[0]):\n",
        "  v = X_ts[i,:,:,0].flatten()\n",
        "  Xtest[i,:] = v\n",
        "\n",
        "\n",
        "lda = LDA()\n",
        "X_train = lda.fit(Xtrain, y_tr)\n",
        "y_test = lda.predict(Xtest)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "classifier = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "\n",
        "classifier.fit(Xtrain, y_tr)\n",
        "y_pred = classifier.predict(Xtest)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cm1 = confusion_matrix(y_ts, y_test)\n",
        "print(cm1)\n",
        "print('Accuracy' + str(accuracy_score(y_ts, y_test)))\n",
        "\n",
        "cm2 = confusion_matrix(y_ts, y_pred)\n",
        "print(cm2)\n",
        "print('Accuracy' + str(accuracy_score(y_ts, y_pred)))"
      ],
      "metadata": {
        "id": "Bf4lTvgszWft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP classifier"
      ],
      "metadata": {
        "id": "mxqp4hy2nUp1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "MLP = models.Sequential([\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='linear'),\n",
        "    layers.Dense(10, activation='linear'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "MLP.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])\n",
        "history = MLP.fit(X_tr, y_tr, epochs=10, \n",
        "                  validation_data=(X_ts, y_ts))\n",
        "test_loss, test_acc = MLP.evaluate(X_ts,  y_ts, verbose=2)"
      ],
      "metadata": {
        "id": "k1fXFL1znTFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN classifier"
      ],
      "metadata": {
        "id": "Q48MqMF5iRZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "CNN = models.Sequential([\n",
        "    layers.Conv2D(3, (2,2), activation='relu', input_shape=(X_tr.shape[1],X_tr.shape[2],1)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(10, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "    ])\n",
        "\n",
        "CNN.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "  metrics=['accuracy'])\n",
        "history = CNN.fit(X_tr, y_tr, epochs=10, \n",
        "                  validation_data=(X_ts, y_ts))\n",
        "test_loss, test_acc = CNN.evaluate(X_ts,  y_ts, verbose=2)"
      ],
      "metadata": {
        "id": "mSE6Bsimg6SP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}